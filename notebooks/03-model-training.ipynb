{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 03 - Model Training and Evaluation\n",
    "\n",
    "**Goal**: Train models to predict NFL game outcomes\n",
    "\n",
    "**My Approach**:\n",
    "- Start simple with XGBoost (usually works well out of the box)\n",
    "- Focus on proper train/test split (no data leakage!)\n",
    "- Evaluate on accuracy first, then dive into what the model learned\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "\n",
    "from src.models.base import XGBoostModel\n",
    "from src.utils.metrics import evaluate_classification, print_evaluation_report\n",
    "\n",
    "# Load our featured data from previous notebook\n",
    "print(\" TODO: Load data with engineered features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preparation\n",
    "\n",
    "**Critical Decision**: How to split train/test?\n",
    "\n",
    "**My Strategy**: Time-based split\n",
    "- Train on 2020-2022 seasons\n",
    "- Test on 2023 season\n",
    "- This mimics real-world usage (predicting future games)\n",
    "- Avoids data leakage from random splits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Temporal train/test split\n",
    "# train_data = df[df['season'].isin([2020, 2021, 2022])]\n",
    "# test_data = df[df['season'] == 2023]\n",
    "# \n",
    "# print(f\"Training games: {len(train_data)}\")\n",
    "# print(f\"Test games: {len(test_data)}\")\n",
    "# print(f\"Training seasons: {sorted(train_data['season'].unique())}\")\n",
    "# print(f\"Test seasons: {sorted(test_data['season'].unique())}\")\n",
    "\n",
    "print(\" TODO: Create temporal train/test split\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Selection\n",
    "\n",
    "**What Goes Into the Model?**\n",
    "- All the rolling averages we created / other features\n",
    "- Matchup differentials (offense vs defense)\n",
    "- Game context (week, home/away)\n",
    "- NOT: team names (want model to generalize), actual scores (would just be overfitting center)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Select features for modeling\n",
    "# exclude_cols = ['game_id', 'season', 'week', 'home_team', 'away_team', \n",
    "#                'home_score', 'away_score', 'point_spread', 'home_win']\n",
    "# \n",
    "# feature_cols = [col for col in train_data.columns if col not in exclude_cols]\n",
    "# print(f\"Using {len(feature_cols)} features:\")\n",
    "# print(feature_cols)\n",
    "\n",
    "print(\"TODO: Select model features\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prepare X and y\n",
    "# X_train = train_data[feature_cols].fillna(0)  # Handle missing values simply\n",
    "# y_train = train_data['home_win'].astype(int)\n",
    "# \n",
    "# X_test = test_data[feature_cols].fillna(0)\n",
    "# y_test = test_data['home_win'].astype(int)\n",
    "# \n",
    "# print(f\"Training features shape: {X_train.shape}\")\n",
    "# print(f\"Test features shape: {X_test.shape}\")\n",
    "\n",
    "print(\" TODO: Prepare X and y arrays\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training\n",
    "\n",
    "**Starting Simple**: XGBoost with default parameters\n",
    "- Usually works well out of the box\n",
    "- Handles missing values automatically\n",
    "- Gives feature importance for free\n",
    "- Can tune hyperparameters later if needed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Train XGBoost model\n",
    "# model = XGBoostModel()\n",
    "# model.fit(X_train, y_train)\n",
    "# \n",
    "# print(\"Model training complete!\")\n",
    "\n",
    "print(\" TODO: Implement XGBoost training\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Evaluation\n",
    "\n",
    "**Key Questions**:\n",
    "1. What's the overall accuracy? (Baseline is ~52-53% for home teams)\n",
    "2. Does the model perform consistently across different types of games?\n",
    "3. What features is the model using most?\n",
    "4. Are there any obvious failure modes?\n",
    "5. Did we run any sort of correlation matrixes on spreads / classificiations to see if featurs actually matter or are we just guessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Basic evaluation\n",
    "# y_pred = model.predict(X_test)\n",
    "# y_prob = model.predict_proba(X_test)[:, 1]  # Probability of home win\n",
    "# \n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f\"Test Accuracy: {accuracy:.3f}\")\n",
    "# print(f\"Baseline (always predict home): {y_test.mean():.3f}\")\n",
    "# \n",
    "# print(\"\\nClassification Report:\")\n",
    "# print(classification_report(y_test, y_pred))\n",
    "\n",
    "print(\" TODO: Evaluate model performance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Importance Analysis\n",
    "\n",
    "**What I Want to Learn**:\n",
    "- Which features actually matter for prediction?\n",
    "- Do the important features make intuitive sense?\n",
    "- Are we missing any obvious features?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Feature importance\n",
    "# feature_importance = model.get_feature_importance()\n",
    "# importance_df = pd.DataFrame({\n",
    "#     'feature': feature_cols,\n",
    "#     'importance': feature_importance\n",
    "# }).sort_values('importance', ascending=False)\n",
    "# \n",
    "# plt.figure(figsize=(10, 8))\n",
    "# sns.barplot(data=importance_df.head(15), x='importance', y='feature')\n",
    "# plt.title('Top 15 Most Important Features')\n",
    "# plt.tight_layout()\n",
    "\n",
    "print(\" TODO: Analyze feature importance\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Interpretation\n",
    "\n",
    "**Sanity Checks**:\n",
    "- Do strong teams beat weak teams more often? (Should see recent win rate as important)\n",
    "- Does home field advantage show up? (Should see some home-specific features)\n",
    "- Are offensive/defensive matchups captured? (Should see differential features)\n",
    "\n",
    "**Red Flags to Watch For**:\n",
    "- Model relying too heavily on one feature (overfitting?)\n",
    "- Important features that don't make football sense\n",
    "- Performance much worse on certain types of games"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Prediction analysis\n",
    "# test_results = test_data.copy()\n",
    "# test_results['predicted_home_win'] = y_pred\n",
    "# test_results['home_win_prob'] = y_prob\n",
    "# \n",
    "# # Look at most confident predictions\n",
    "# confident_predictions = test_results[\n",
    "#     (test_results['home_win_prob'] > 0.8) | (test_results['home_win_prob'] < 0.2)\n",
    "# ]\n",
    "# print(f\"High confidence predictions: {len(confident_predictions)}\")\n",
    "# print(f\"Accuracy on high confidence: {(confident_predictions['home_win'] == confident_predictions['predicted_home_win']).mean():.3f}\")\n",
    "\n",
    "print(\" TODO: Analyze prediction confidence\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Error Analysis\n",
    "\n",
    "**Learning from Mistakes**: Look at games where the model was most wrong\n",
    "- Big upsets the model didn't see coming\n",
    "- Games where model was overconfident\n",
    "- Patterns in the mistakes (certain teams, certain situations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: Error analysis\n",
    "# test_results['prediction_error'] = np.abs(test_results['home_win_prob'] - test_results['home_win'])\n",
    "# worst_predictions = test_results.nlargest(10, 'prediction_error')\n",
    "# \n",
    "# print(\"Worst predictions (biggest errors):\")\n",
    "# print(worst_predictions[['home_team', 'away_team', 'home_win', 'home_win_prob', 'prediction_error']])\n",
    "\n",
    "print(\" TODO: Analyze worst predictions\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Training Insights\n",
    "\n",
    "**What I Expect to Learn**:\n",
    "1. **Accuracy**: Probably 55-65% if features are good\n",
    "2. **Key Features**: Recent win rate, point differentials, home field\n",
    "3. **Model Behavior**: Should be more confident on mismatches, less on even games\n",
    "4. **Limitations**: Probably struggles with injuries, weather, motivation\n",
    "\n",
    "**Success Criteria**:\n",
    "-  Beat baseline (random guessing ~50%, always home ~53%)\n",
    "-  Features make football sense\n",
    "-  Performance consistent across different game types\n",
    "-  High-confidence predictions are more accurate\n",
    "\n",
    "**Next Steps**:\n",
    "- If model works: Try ensemble methods, hyperparameter tuning\n",
    "- If model struggles: Better features, more data, different approach\n",
    "- Either way: Deploy for 2024 season predictions!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
